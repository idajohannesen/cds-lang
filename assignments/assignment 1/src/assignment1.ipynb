{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, install spacy, pandas, and the language model in the terminal, by typing in:\n",
    "# pip install spacy pandas\n",
    "# python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_900/2223173363.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folderpath = os.path.join(\"../input/USEcorpus/a1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a path to the corpus containing our data and then sort the directory\n",
    "main_folder_path = \"../input/USEcorpus/\"\n",
    "sorted_dir = sorted(os.listdir(main_folder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1164528371.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[12], line 2\u001b[0;36m\u001b[0m\n\u001b[0;31m    text=file.read()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# with open(folder_path, \"r\", encoding=\"latin-1\") as file:\n",
    "    text=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing: removing all tokens that simply document metadata or identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a for loop going into each subfolder in the corpus and opening all text files within the subfolders\n",
    "for folder in sorted_dir:\n",
    "    folder_path = os.path.join(main_folder_path, folder)\n",
    "    filenames = sorted(os.listdir(folder_path))\n",
    "    for text_file in filenames:\n",
    "        file_path = folder_path + \"/\" + text_file\n",
    "        with open (file_path, encoding=\"latin-1\") as file:\n",
    "            text = file.read()\n",
    "       # add text files to a doc object\n",
    "        doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<doc.id=0502.c1>\n",
      "<title> How the understanding of Wuthering Heights is affected by the structure and the two narrators </title>\n",
      "In this essay I will discuss the effect with the dual narrators in Wuthering Heights. I will also look at the structure and see what effect that has for the story. Does the book become more interesting with the two narrators, and does the structure contribute to make the story better or does the book become less interesting to read with this construction? First I will discuss the two narrators before I comment on the structure.\n",
      "\t The main narrator is Mr. Lockwood but within his story Nelly is the narrator. I think Emily Bronte has chosen Mr. Lockwood as the main narrator to make the story more reliable. He is a man and he comes from the upper class while Nelly is a female servant. When the book was written it was more accepted with a male narrator than with a female, and I think that is why Bronte has chosen Mr. Lockwood as her principal narrator.\n",
      "\t Another reason for having two narrators is because it gives us different perspectives. As we all know there are always two sides to a story and here it is up to us to use our own judgement. We can either trust Nelly's story as she tells it to Mr. Lockwood, or we can keep in mind that stories change as times goes on and that she cannot take the other's thoughts into account. As you can read in \"The almanac and the window: narrative, time and viewpoint in the structure of Wuthering Heights\": we are continually reminded how everything we read is subjective - conditioned by the attitudes, preconceptions, limitations, or plain bias, of narrators whose only existence is within the conflicts of the text itself. None of them can be totally objective, none can be the ultimate judge of everything that goes on. (p. 16)\n",
      "\t What makes Nelly's story reliable is that \"she has known and experienced it all and can tell it as a story\". (p. 83, \"Story and history in Wuthering Heights\") She has the general facts in her hand but she can obviously not give us more than her own experiences and thoughts. Because of this she fails to give us the true story, it is only true in her own eyes, we do not find out what Heatcliff thinks and how he really is nor do we find out what the other characters think.\n",
      "\t Why does Emily Bronte choose to have Mr. Lockwood in the story, besides that he is a man and that it makes the story more reliable? Nelly is the one that knows the story as it has happened and she has to tell Lockwood the story since he has made some blunders. In the beginning he visits the Heights and guesses wrong and says to himself \"Perceiving myself in a blunder, I attempt to correct it\" (p. 27, Wuthering Heights) and then he makes another mistake in the same page by guessing wrong again and thinks \"This was worse than before/.../\". When he returns home to the Grange he has to ask the housekeeper how the matters stand. The story gets a reason to be told in this way. Mr. Lockwood shares the reader's wonders.\n",
      "\t From this we can jump to the structure. The story begins in 1801 and ends in 1802 - which is the frame story. After Lockwood's visit to the Heights in 1801 he comes back to the Grange and it is here that Nelly's story begins. She tells him the story of the Earnshaw family. Lockwood knows just as must as we readers know and therefor we want to find out the same thing. He appears in the story to make us curious. Our curiosity is aroused almost immediately, when Mr. Lockwood visits Wuthering Heights. We want to find out why Catherine is so dull and why Heatcliff is so ruff.\n",
      "\t Bronte has chosen to rise our curiosity through Lockwood's questions. They appear in the book at intervals to remind us why and to whom the story is being told. On page 43 Lockwood asks Nelly about the Earnshaw family - the ones he met when he went to visit his neighbours at Wuthering Heights. When the clock strikes eleven Nelly wants to end her telling, but Lockwood want to hear more and he says \" Sit still, Mrs. Dean /.../do sit still another half-hour!\" (p.64). The other day Lockwood wants Nelly to continue on were she stopped. Heatcliff has left for America and Lockwood asks \" Did he finish his education on the Continent, and come back a gentleman?\" (p. 88). \n",
      "\t On page 139 Lockwood continues the story in Nelly's own words. He says \"She is, on the whole, a very fair narrator, and I don't think I could improve her style.\" (p. 139, Wuthering Heights.) The story continues to page 248 and is told in I-form, which I think sounds confusing. It is after all Lockwood who tells the story and not Nelly. He should have said Nelly instead of I, but on the other hand he says that he cannot improve her style. Maybe that's why he never changes perspective. After he has finished her story he leaves the Grange for London. In chapter 31 he returns to the Grange and finds out that Heatcliff has died. \"Lockwood is almost as confused and disoriented this time as he was before /.../\" (p. 95, \"Story and history in Wuthering Heights\"). He then asks the final question and is filled out what has happened while he was gone. \" 'Heatcliff dead!' I exclaimed, astonished. 'How long ago?'\" (p. 257, Wuthering Heights).\n",
      "\t By letting Lockwood leave the place for London and then have him back in the story again is a genius trick to tie the sack together. Then everything that has happened can be linked to the present and the story gets a meaning to be told since it is still up to date. It is like a red thread leaping through the story. It starts with Lockwood's visit to Wuthering Heights and then Nelly informs him of the past starting when Heatcliff comes to the Heights. Then Nelly fills out the story so much that that it ends just before Lockwood's visits to the Heights. Then he leaves and comes back and has to be informed again before he ends the story by visiting their graves. Lockwood's own words open and close the book - he is the main character and he also creates the structure.\n",
      "\t In what ways do all this affect the total view of the book and the understanding of it? I think it makes the book easier to read and it becomes more interesting. We as readers tend to identify ourselves with Mr. Lockwood and his questions help us understand the book. His questions make us interested, and they also help Nelly trough the story. Even if Nelly fails to give us the other's thoughts and experiences it is reliable, we have to bear in mind that the story is not about Heatcliff or any other person in the book. It is about the lives of the persons influenced direct or indirect by Wuthering Heights - as the title also suggest. The book also becomes more interesting when we don't find out everything; it is up to us to judge why and how things happened. You can say that Lockwood is the most important narrator in the book, but without Nelly there would not have been a story. But it is not for the total view of the book when Mr. Lockwood tells the story in I-form. I got very confused there - is he the narrator or is it Nelly - but after all they create the story together.\n",
      "\t \n",
      "\n",
      "References\n",
      "\n",
      "Bronte, Emily, Wuthering Heights, Penguin Popular Classics (London, 1994)\n",
      "\n",
      "Norgate, Paul, \"The almanack and the window: narrative, time and viewpoint in the structure of Wuthering Heights\", Longman Critical Essays, Eds. L. Cookson and B. Longlerey\n",
      "\n",
      "Vogler, Thomas A., \"Story and History in Wuthering Heights\"\n",
      "\n",
      "Woodring, Carl R., \"The Narrators of Wuthering Heights\"\n",
      "</doc>\n"
     ]
    }
   ],
   "source": [
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L. Cookson', 'Vogler', 'B. Longlerey\\n\\n', '43', 'Paul', 'Earnshaw', 'Thomas A.', 'Heights', 'Catherine', '27', 'Wuthering Heights', 'America', 'another half-hour', 'Bronte', 'Dean', 'Story and History in Wuthering Heights', '1802', '88', 'Norgate', 'chapter 31', 'Grange', 'Heatcliff', '83', 'eleven', '16', 'First', '248', 'Emily Bronte', 'Nelly', 'Longman Critical Essays, Eds', 'ruff', '139', 'Carl R.', 'The Narrators of Wuthering Heights', 'Woodring', '95', '1801', 'London', '1994', 'two', 'Lockwood', '257'}\n"
     ]
    }
   ],
   "source": [
    "# create empty list\n",
    "entities = []\n",
    "\n",
    "# add each entity to list\n",
    "for ent in doc.ents:\n",
    "    entities.append(ent.text)\n",
    "print(set(entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create counters for nouns, verbs, adjectives, and adverbs.\n",
    "noun_count = 0\n",
    "verb_count = 0\n",
    "adj_count = 0\n",
    "adv_count = 0\n",
    "\n",
    "# with a for loop, add 1 to the counter every time that part of speech appears in the doc object\n",
    "for token in doc:\n",
    "    if token.pos_ == \"NOUN\":\n",
    "        noun_count += 1\n",
    "    elif token.pos_ == \"VERB\":\n",
    "        verb_count += 1\n",
    "    elif token.pos_ == \"ADJ\":\n",
    "        adj_count += 1\n",
    "    elif token.pos_ == \"ADV\":\n",
    "        adv_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1378.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculating the relative frequency of each part of speech per 10,000 words\n",
    "relative_freq_noun = (noun_count/len(doc)) * 10000\n",
    "round(relative_freq_noun, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1453.86"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_verb = (verb_count/len(doc)) * 10000\n",
    "round(relative_freq_verb, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518.33"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_adj = (adj_count/len(doc)) * 10000\n",
    "round(relative_freq_adj, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "695.32"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_freq_adv = (adv_count/len(doc)) * 10000\n",
    "round(relative_freq_adv, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n"
     ]
    }
   ],
   "source": [
    "# extracting named entities for persons, locations, and organizations\n",
    "persons = set()\n",
    "for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            persons.add(ent.text)\n",
    "\n",
    "num_persons = len(persons)\n",
    "print(num_persons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "locations = set()\n",
    "for ent in doc.ents:\n",
    "        if ent.label_ == 'LOC':\n",
    "            locations.add(ent.text)\n",
    "\n",
    "num_locations = len(locations)\n",
    "print(num_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "organisations = set()\n",
    "for ent in doc.ents:\n",
    "        if ent.label_ == 'ORG':\n",
    "            organisations.add(ent.text)\n",
    "\n",
    "num_organisations = len(organisations)\n",
    "print(num_organisations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = []\n",
    "for token in doc:\n",
    "    annotations.append((token.text, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "8 columns passed, passed data had 2 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:939\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 939\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    940\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:986\u001b[0m, in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    984\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_mi_list \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(columns) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(content):  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39m# caller's responsibility to check for this...\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    987\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(columns)\u001b[39m}\u001b[39;00m\u001b[39m columns passed, passed data had \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(content)\u001b[39m}\u001b[39;00m\u001b[39m columns\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m     )\n\u001b[1;32m    990\u001b[0m \u001b[39mif\u001b[39;00m is_mi_list:\n\u001b[1;32m    991\u001b[0m     \u001b[39m# check if nested list column, length of each sub-list should be equal\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 8 columns passed, passed data had 2 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/work/Language Analytics/cds-lang/assignments/assignment 1/src/assignment1.ipynb Cell 22\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5019582-0.cloud.sdu.dk/work/Language%20Analytics/cds-lang/assignments/assignment%201/src/assignment1.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# creating a dataframe with pandas using the spaCy doc\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://app-5019582-0.cloud.sdu.dk/work/Language%20Analytics/cds-lang/assignments/assignment%201/src/assignment1.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# make one per subfolder\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://app-5019582-0.cloud.sdu.dk/work/Language%20Analytics/cds-lang/assignments/assignment%201/src/assignment1.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(annotations, \n\u001b[1;32m      <a href='vscode-notebook-cell://app-5019582-0.cloud.sdu.dk/work/Language%20Analytics/cds-lang/assignments/assignment%201/src/assignment1.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m                     columns\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mFilename\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mRelFreq NOUN\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mRelFreq VERB\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mRelFreq ADJ\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mRelFreq ADV\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mUnique PER\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mUnique LOC\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mUnique ORG\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:840\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    838\u001b[0m     \u001b[39mif\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    839\u001b[0m         columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[0;32m--> 840\u001b[0m     arrays, columns, index \u001b[39m=\u001b[39m nested_data_to_arrays(\n\u001b[1;32m    841\u001b[0m         \u001b[39m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[39;49;00m\n\u001b[1;32m    842\u001b[0m         \u001b[39m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[39;49;00m\n\u001b[1;32m    843\u001b[0m         data,\n\u001b[1;32m    844\u001b[0m         columns,\n\u001b[1;32m    845\u001b[0m         index,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    846\u001b[0m         dtype,\n\u001b[1;32m    847\u001b[0m     )\n\u001b[1;32m    848\u001b[0m     mgr \u001b[39m=\u001b[39m arrays_to_mgr(\n\u001b[1;32m    849\u001b[0m         arrays,\n\u001b[1;32m    850\u001b[0m         columns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    853\u001b[0m         typ\u001b[39m=\u001b[39mmanager,\n\u001b[1;32m    854\u001b[0m     )\n\u001b[1;32m    855\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:520\u001b[0m, in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    517\u001b[0m \u001b[39mif\u001b[39;00m is_named_tuple(data[\u001b[39m0\u001b[39m]) \u001b[39mand\u001b[39;00m columns \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    518\u001b[0m     columns \u001b[39m=\u001b[39m ensure_index(data[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39m_fields)\n\u001b[0;32m--> 520\u001b[0m arrays, columns \u001b[39m=\u001b[39m to_arrays(data, columns, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    521\u001b[0m columns \u001b[39m=\u001b[39m ensure_index(columns)\n\u001b[1;32m    523\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:845\u001b[0m, in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    842\u001b[0m     data \u001b[39m=\u001b[39m [\u001b[39mtuple\u001b[39m(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m data]\n\u001b[1;32m    843\u001b[0m     arr \u001b[39m=\u001b[39m _list_to_arrays(data)\n\u001b[0;32m--> 845\u001b[0m content, columns \u001b[39m=\u001b[39m _finalize_columns_and_data(arr, columns, dtype)\n\u001b[1;32m    846\u001b[0m \u001b[39mreturn\u001b[39;00m content, columns\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:942\u001b[0m, in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    939\u001b[0m     columns \u001b[39m=\u001b[39m _validate_or_indexify_columns(contents, columns)\n\u001b[1;32m    940\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m    941\u001b[0m     \u001b[39m# GH#26429 do not raise user-facing AssertionError\u001b[39;00m\n\u001b[0;32m--> 942\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(err) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m    944\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(contents) \u001b[39mand\u001b[39;00m contents[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mobject_:\n\u001b[1;32m    945\u001b[0m     contents \u001b[39m=\u001b[39m convert_object_array(contents, dtype\u001b[39m=\u001b[39mdtype)\n",
      "\u001b[0;31mValueError\u001b[0m: 8 columns passed, passed data had 2 columns"
     ]
    }
   ],
   "source": [
    "# creating a dataframe with pandas using the spaCy doc\n",
    "# make one per subfolder\n",
    "data = pd.DataFrame(annotations, \n",
    "                    columns=[\"Filename\", \"RelFreq NOUN\", \"RelFreq VERB\", \"RelFreq ADJ\", \"RelFreq ADV\", \"Unique PER\", \"Unique LOC\", \"Unique ORG\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RelFreq NOUNS</th>\n",
       "      <th>RelFreq VERB</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>doc.id=0502.c1</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&gt;</td>\n",
       "      <td>SYM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1573</th>\n",
       "      <td>\"</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1574</th>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1575</th>\n",
       "      <td>&lt;</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>/doc</td>\n",
       "      <td>PUNCT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>&gt;</td>\n",
       "      <td>X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1578 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RelFreq NOUNS RelFreq VERB\n",
       "0                  <            X\n",
       "1     doc.id=0502.c1            X\n",
       "2                  >          SYM\n",
       "3                 \\n        SPACE\n",
       "4                  <            X\n",
       "...              ...          ...\n",
       "1573               \"        PUNCT\n",
       "1574              \\n        SPACE\n",
       "1575               <            X\n",
       "1576            /doc        PUNCT\n",
       "1577               >            X\n",
       "\n",
       "[1578 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload dataframe to output folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "issues:\n",
    "- weird tokens? how to preprocess\n",
    "- takes the last file instead of going through all of them - need to somehow append every file's text to the existing doc object\n",
    "- cant make data frame with more than two columns\n",
    "- add in the rest of the tasks to the loop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
